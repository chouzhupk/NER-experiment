{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CoNLL-2003 (https://www.clips.uantwerpen.be/conll2003/ner/) is a well-known data set for named entity recognition (NER) task, which provides the part-of-speech (POS) tag, chunking tag (for phrase) and name entity tag for every word in one line. The end of sentence corresponds to an empty line in the file.\n",
    "\n",
    "In terms of the name entity tags, the data highlights those for **organization** (**I-ORG**), **person** (**I-PER**) and **location** (**I-LOC**), and marks the rest names as **miscellaneous** (**I-MISC**). Null label **O** is assigned to words that are not (part of) a name. \n",
    "\n",
    "Besides, there are certain situations that two phrases of the same type immediately follow each other, the first word of the second phrase is **B**-initialized instead to distinguish. For instance, \"...Golan (I-LOC) Heights (I-LOC) Israel (**B-LOC**)...\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Embedding, Dense, Bidirectional, LSTM, TimeDistributed, Dropout\n",
    "\n",
    "pd.options.display.max_rows = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the training data, index the sentences, and remove the prefix (I and B) of entity tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/CoNLL-2003/eng.train\", names=[\"word\", \"POS\", \"chunk\", \"origin_entity\"], \n",
    "                    header=None, sep=\" \", skip_blank_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop prefix of name entity tag\n",
    "train[\"entity\"] = train[\"origin_entity\"].str.rsplit(\"-\", 1).str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sentence number\n",
    "train[\"sentence\"] = train.isnull().all(axis=1).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no longer needs the empty rows after indexing the sentences\n",
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode the name entity tags and words (one-hot for tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_tag_encoder = LabelEncoder()\n",
    "train['y'] = entity_tag_encoder.fit_transform(train.entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  6.96900000e+03,   3.09300000e+03,   1.72900000e+03,\n",
       "          1.47000000e+03,   1.16400000e+03,   4.29000000e+02,\n",
       "          1.09000000e+02,   1.70000000e+01,   2.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00]),\n",
       " array([   1.        ,    8.46666667,   15.93333333,   23.4       ,\n",
       "          30.86666667,   38.33333333,   45.8       ,   53.26666667,\n",
       "          60.73333333,   68.2       ,   75.66666667,   83.13333333,\n",
       "          90.6       ,   98.06666667,  105.53333333,  113.        ]),\n",
       " <a list of 15 Patch objects>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a look at the length distribution of sentences, most of which falls below 60\n",
    "plt.hist(train.groupby('sentence').agg('count')['word'], bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_encoder = LabelEncoder()\n",
    "train['x'] = word_encoder.fit_transform(train.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder = LabelBinarizer()\n",
    "onehot_encoder.fit(train.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sentence = train.groupby('sentence')['x'].apply(list)\n",
    "y_train_tag = train.groupby('sentence')['y'].apply(list)\n",
    "y_train_tag_onehot = [onehot_encoder.transform(group) for group in y_train_tag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad (encoded) sentences and tags to the unifed length 60. (accuracy upper bound ~ .7842)\n",
    "* Increasing length to 100 shifts the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = pad_sequences(x_train_sentence, maxlen=100, value=-1)\n",
    "y_train_seq = pad_sequences(y_train_tag_onehot, maxlen=100, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word embedding with 50 dimensional GloVe pretrained word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GloVe = pd.read_table('data/glove.6B.50d.txt', index_col=0, header=None, sep=' ', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "embedding_matrix = np.zeros((len(word_encoder.classes_) + 1, 50))\n",
    "for i, word in enumerate(word_encoder.classes_):\n",
    "    try:\n",
    "        embedding_matrix[i] = GloVe.loc[word]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_15 (Embedding)     (None, 100, 50)           1181150   \n",
      "_________________________________________________________________\n",
      "bidirectional_15 (Bidirectio (None, 100, 550)          717200    \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 100, 5)            2755      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100, 5)            0         \n",
      "=================================================================\n",
      "Total params: 1,901,105\n",
      "Trainable params: 1,901,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_ = Input(shape=(100,))\n",
    "x_ = Embedding(*embedding_matrix.shape, weights=[embedding_matrix])(input_)\n",
    "x_ = Bidirectional(LSTM(275, return_sequences=True))(x_)\n",
    "x_ = TimeDistributed(Dense(5, activation='softmax'))(x_)\n",
    "x_ = Dropout(0.5)(x_)\n",
    "model = Model(inputs=input_, outputs=x_)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14984/14984 [==============================] - 37s 2ms/step - loss: 0.0097 - acc: 0.8650\n",
      "Epoch 2/5\n",
      "14984/14984 [==============================] - 37s 2ms/step - loss: 1.6100e-08 - acc: 0.8705\n",
      "Epoch 3/5\n",
      "14984/14984 [==============================] - 37s 2ms/step - loss: 1.6100e-08 - acc: 0.8705\n",
      "Epoch 4/5\n",
      "14984/14984 [==============================] - 39s 3ms/step - loss: 1.6100e-08 - acc: 0.8705\n",
      "Epoch 5/5\n",
      "14984/14984 [==============================] - 38s 3ms/step - loss: 1.6100e-08 - acc: 0.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9f2756e3d0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_seq, y_train_seq, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and encode test data and encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/CoNLL-2003/eng.testa', names=[\"word\", \"POS\", \"chunk\", \"origin_entity\"], \n",
    "                    header=None, sep=\" \", skip_blank_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop prefix of name entity tag\n",
    "test[\"entity\"] = test[\"origin_entity\"].str.rsplit(\"-\", 1).str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sentence number\n",
    "test[\"sentence\"] = test.isnull().all(axis=1).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no longer needs the empty rows after indexing the sentences\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['y'] = entity_tag_encoder.transform(test.entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires a little workaround to solve the out-of-bag words encoding for `fit` method of `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_map = {word: idx for idx, word in enumerate(word_encoder.classes_)}\n",
    "test['x'] = test['word'].apply(lambda x: word_map.get(x, len(word_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         5313\n",
       "1          111\n",
       "2        23622\n",
       "3        12467\n",
       "4        10252\n",
       "5         3924\n",
       "6        12519\n",
       "7         3850\n",
       "8         7933\n",
       "9        13045\n",
       "10         123\n",
       "12        8816\n",
       "13        1407\n",
       "15       13380\n",
       "16        8029\n",
       "         ...  \n",
       "55025    23622\n",
       "55026    19476\n",
       "55027    13689\n",
       "55028    22909\n",
       "55029    19431\n",
       "55030    23622\n",
       "55031    18975\n",
       "55032    22423\n",
       "55033    19476\n",
       "55034    12736\n",
       "55035      123\n",
       "55037      112\n",
       "55038     6189\n",
       "55039    10058\n",
       "55040    23622\n",
       "Name: x, Length: 50934, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
